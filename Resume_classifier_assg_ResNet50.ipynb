{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VdLIkpCxE1BW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3Quxv02E9Iw"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WI49S88ozqMM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQL_Ux1IE9LX"
      },
      "outputs": [],
      "source": [
        "def resize_images(input_folder, output_folder, target_size=(600, 800)):\n",
        "    \n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Resize the image to the target size\n",
        "        img_resized = img.resize(target_size, Image.ANTIALIAS)\n",
        "\n",
        "        # Save the resized image to the output folder\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        img_resized.save(output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OMKcZ-gLE9N2"
      },
      "outputs": [],
      "source": [
        "def augment_images(input_folder, output_folder, augment_size=10):\n",
        "    # Set up data augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate through each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Convert the image to a NumPy array and resize\n",
        "        img_array = np.array(img.resize((600, 800)).convert(\"RGB\"))\n",
        "\n",
        "        img_array = img_array.reshape((1,) + img_array.shape)\n",
        "\n",
        "        # Apply data augmentation and save augmented images\n",
        "        i = 0\n",
        "        for batch in datagen.flow(img_array, batch_size=1, save_to_dir=output_folder, save_prefix='augmented', save_format='png'):\n",
        "            i += 1\n",
        "            if i >= augment_size:\n",
        "                break  # Break after generating the specified number of augmented images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG_ELEEhE9QW",
        "outputId": "ae36f432-fde0-4cc2-a80b-8a56d93ccb1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-f2626d97deb4>:14: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img_resized = img.resize(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ],
      "source": [
        "# Resizing non-resume images\n",
        "resize_images('/content/drive/MyDrive/Bureau_assignment/Dataset/Non-resume', '/content/drive/MyDrive/Bureau_assignment/Dataset/non-res_resized')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hloEVN3hKHC_"
      },
      "outputs": [],
      "source": [
        "# Augmenting non resume resized images\n",
        "augment_images('/content/drive/MyDrive/Bureau_assignment/Dataset/non-res_resized', '/content/drive/MyDrive/Bureau_assignment/Dataset/augmented_non-res', augment_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuu3GncTE9Sm",
        "outputId": "0c6e7fac-5ca0-4882-cb1f-f9a8b96827f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-f2626d97deb4>:14: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img_resized = img.resize(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ],
      "source": [
        "# Resizing resume images\n",
        "resize_images('/content/drive/MyDrive/Bureau_assignment/Dataset/Resume', '/content/drive/MyDrive/Bureau_assignment/Dataset/res_resized')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nqKQgn6uE9VA"
      },
      "outputs": [],
      "source": [
        "# Augmenting non resume resized images\n",
        "augment_images('/content/drive/MyDrive/Bureau_assignment/Dataset/res_resized', '/content/drive/MyDrive/Bureau_assignment/Dataset/augmented_res', augment_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-RT4WkaE9XZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhrPSWz0xGaY",
        "outputId": "fa395055-f848-4ef7-dbd1-3144cdb47ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2647 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "82/82 [==============================] - 86s 977ms/step - loss: 1.2365 - accuracy: 0.5453\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 81s 981ms/step - loss: 0.6209 - accuracy: 0.6478\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 82s 989ms/step - loss: 0.6567 - accuracy: 0.6352\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 81s 978ms/step - loss: 0.5424 - accuracy: 0.7174\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 82s 988ms/step - loss: 0.4831 - accuracy: 0.7686\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 82s 987ms/step - loss: 0.4420 - accuracy: 0.8057\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 82s 990ms/step - loss: 0.4559 - accuracy: 0.7813\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 82s 990ms/step - loss: 0.4052 - accuracy: 0.8141\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 82s 993ms/step - loss: 0.3942 - accuracy: 0.8233\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 82s 989ms/step - loss: 0.3697 - accuracy: 0.8359\n"
          ]
        }
      ],
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Bureau_assignment/Dataset/Augmented_dataset'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (600, 800)\n",
        "batch_size = 32\n",
        "\n",
        "# Set up data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',  # As it is a binary classification task\n",
        "    shuffle=True  # For training its better to shuffle the images for more randomness\n",
        ")\n",
        "\n",
        "# Load ResNet50 model with pre-trained weights (excluding top layers)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(600, 800, 3))\n",
        "\n",
        "# we freeze the layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# we can add some extra classification layers\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AiC1bkt-KO1",
        "outputId": "6737bbea-1779-46fa-9e98-172298f8ae86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "\n",
        "model.save('resnet50_resume_classifier.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS339OvixGmJ",
        "outputId": "f102f8da-16c6-401e-9611-abbd8ec74d26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<keras.src.engine.input_layer.InputLayer at 0x7a7730bab070>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7a77501b9240>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7730ba9f60>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a770520cbb0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7730a7f6d0>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x7a7704f88280>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7a7704f88ca0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704f8a110>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704f8bc10>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704f8bd30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704f88820>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704f8ba30>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704f8ba60>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7730a7df30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704facdf0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704f8a3e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704fad270>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704f8aec0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704fafbb0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704faf070>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704fad2a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704faf910>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704fafcd0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704fafc70>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704fd1180>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704fd29e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704fd3cd0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704fd10f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704fd3c40>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704fd31c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704fd30d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ff0cd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ff2350>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ff3340>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ff3f70>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ff1c30>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ff1ba0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704ff3af0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ff0700>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704faed40>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ff2680>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704fad420>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704fd0580>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704f8abf0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704f8ab90>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704fd3eb0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e21b70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ff36d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e22a10>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704f89810>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e20b20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e23a00>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e22fe0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e3c9a0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e3df90>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e3ef80>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e3e890>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e3fee0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e3ca90>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e3dcc0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e3da20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e55030>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e569b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e56470>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e56ef0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e54910>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e55bd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e570a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e55cf0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e56c50>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e7c580>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e7d6f0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e7ec80>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e7f760>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e7fc40>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e7ed10>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e7fbe0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e7c670>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e551b0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e7fca0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e54700>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e7e3e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e22860>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e7eb30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e9dfc0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e9eaa0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e9f3d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e20610>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e9e5f0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704f88c70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e9ee60>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e9e110>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e65b40>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e666b0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e67190>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e669b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e67700>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e65030>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e67820>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ec0280>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ec23b0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e67430>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ec2b60>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ec0a90>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ec0910>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ec3d90>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ec3010>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ec1b40>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ec2e30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ee1d80>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ee2320>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704ec3640>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ee3af0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ee1570>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ee16f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ee3fd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ee15d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ee2740>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704ee09d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704ec27d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704e9ff70>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704e3f6a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704e64070>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e9d3c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704ee1ab0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704504340>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704506c50>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704507c70>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704507c40>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704507ee0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045059c0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a77045069b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a77045220b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704520b20>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045236d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704523190>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a77045234c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704523520>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704522920>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704535ba0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045368f0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704523970>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704537040>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704536dd0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704534ee0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704537850>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a770455da50>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a770455f2e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770455ec20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704537250>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a770455f8e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045235b0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a770455ff70>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a770455e350>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770455fe20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a770455ddb0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704536e90>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704535390>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704535510>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704520520>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a7704534850>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704e9eb30>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a7704506e30>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a7704523f10>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770457aaa0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a770457ac50>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045794e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770457bcd0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a7704579ba0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a77045780a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770457b7c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7a770459dcc0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7a770459e260>,\n",
              " <keras.src.layers.merging.add.Add at 0x7a770457b250>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7a770459fa30>,\n",
              " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x7a787571bbb0>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a770455f460>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7a77045b6440>]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WnYH4fr4xGsR"
      },
      "outputs": [],
      "source": [
        "# For loading the saved model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# model = load_model('/content/resnet50_resume_classifier_new.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW8CNSXMxGwr",
        "outputId": "bafcca65-38f1-4e4c-d1fc-f26687ed81d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Prediction: Non-Resume\n"
          ]
        }
      ],
      "source": [
        "# Function to preprocess an image for prediction\n",
        "def preprocess_image(img_path, target_size=(600, 800)):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array / 255.0  # Normalize the pixel values to the range [0, 1]\n",
        "\n",
        "# Make predictions on a single image\n",
        "test_image_path = '/content/drive/MyDrive/Bureau_assignment/Dataset/Test_dataset/non-resume/Screenshot 2023-12-30 234940.png'  # Replace with the path to the test image\n",
        "preprocessed_image = preprocess_image(test_image_path)\n",
        "\n",
        "# prediction\n",
        "prediction = model.predict(preprocessed_image)\n",
        "\n",
        "if prediction > 0.5:\n",
        "    print(\"Prediction: Resume\")\n",
        "else:\n",
        "    print(\"Prediction: Non-Resume\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yazIn5AAxG0I",
        "outputId": "57fe6558-f8df-44b9-e88a-d86b3926bd4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 42 images belonging to 2 classes.\n",
            "2/2 [==============================] - 2s 321ms/step - loss: 0.6209 - accuracy: 0.7381\n",
            "Test Loss: 0.6208658814430237, Test Accuracy: 0.738095223903656\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Bureau_assignment/Dataset/Test_dataset',\n",
        "    target_size=(600, 800),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # No need to shuffle for test dataset\n",
        ")\n",
        "\n",
        "evaluation = model.evaluate(test_generator)\n",
        "print(f'Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-kPnYWbBxG3g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zURNIKJ_xG66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_jSrPULxG-J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFGU3yz3xHBI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tePh6hnOxHEb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzuND3tExHHI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpvVsU_1xHKB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWsCNn4txHNR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyjKlBcNxHQL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-wYlilpxHTJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wggrec-5xHWR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBMC5m37E9Zo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
